{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DECYx_h7aaqs"
      },
      "source": [
        "# Implement a CNN for CIFAR-10 (With Custom Layers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tasks was taken from: https://github.com/Exorust/TorchLeet/tree/main/torch/medium\n",
        "\n",
        "## Problem Statement\n",
        "You are tasked with implementing a **Convolutional Neural Network (CNN)** for image classification on the **CIFAR-10** dataset using PyTorch. However, instead of using PyTorch's built-in `nn.Conv2d` and `nn.MaxPool2d`, you must implement these layers **from scratch** using `nn.Module`. Your model will include convolutional layers for feature extraction, pooling layers for downsampling, and fully connected layers for classification.\n",
        "\n",
        "### Requirements\n",
        "1. **Implement Custom Layers:**\n",
        "   - Create a custom `Conv2dCustom` class that mimics the behavior of `nn.Conv2d`.\n",
        "   - Create a custom `MaxPool2dCustom` class that mimics the behavior of `nn.MaxPool2d`.\n",
        "2. **Define the CNN Model:**\n",
        "   - Use `Conv2dCustom` for convolutional layers.\n",
        "   - Use `MaxPool2dCustom` for pooling layers.\n",
        "   - Use standard `nn.Linear` for fully connected layers.\n",
        "   - The model should process input images of shape `(3, 32, 32)` as in the CIFAR-10 dataset.\n",
        "\n",
        "### Constraints\n",
        "   - You must not use `nn.Conv2d` or `nn.MaxPool2d`. Use your own custom implementations.\n",
        "   - The CNN should include multiple convolutional and pooling layers, followed by fully connected layers.\n",
        "   - Ensure the model outputs class predictions for **10 classes**, as required by CIFAR-10.\n",
        "\n",
        "**! Hint:**\n",
        "   - Define `Conv2dCustom` and `MaxPool2dCustom` as subclasses of `nn.Module`. - Use nested loops and tensor slicing to perform the operations.\n",
        "   - In `CNNModel.__init__`, use these custom layers to build the architecture.\n",
        "   - Implement the forward pass to pass inputs through convolution, activation, pooling, flattening, and fully connected layers.\n",
        "\n",
        "### Code template"
      ],
      "metadata": {
        "id": "4L12POpZPL2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMQo9TYHaaqx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "class Conv2dCustom(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "class MaxPool2dCustom(nn.Module):\n",
        "    def __init__(self, kernel_size, stride=None):\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "# Define the CNN Model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Output: 32x32x32\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNNModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for images, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "### Rephrase\n",
        "\n",
        "- Implement convolution and pooling - it involves intensive work with multidimensional tensors (`[batch, channels, height, width]`)\n",
        "   - work with `view(), permute(), reshape(), transpose(), expand(), repeat()`\n",
        "   - Implement complex indexing and slicing\n",
        "- Initialization of scales\n",
        "- Calculating gradients\n",
        "- include multiple convolutional and pooling layers, followed by fully connected layers\n",
        "- Ensure the model outputs class predictions for 10 classes, as required by CIFAR-10.\n",
        "\n",
        "### Ideas behined\n",
        "\n",
        "The key goal of this task is to break down the barrier between the \"user\" of a neural network and its \"creator.\"\n",
        "\n",
        "Using `nn.Conv2d` is the user level. You know what it does and can use it.\n",
        "\n",
        "Implementing `Conv2dCustom` is the developer/researcher level. You know how it works and can create one from scratch. This transition is crucial for professional growth in Machine Learning.\n",
        "\n",
        "So, even if you always use built-in modules in real work, this experience will give you invaluable insights that will help you debug models more effectively, design new architectures, and gain a deeper understanding of the underlying processes.\n",
        "\n",
        "### Implementing note\n",
        "\n",
        "- Formally nn.Conv2d uses Cross-correlation, so we are not going to rotate the core matrix"
      ],
      "metadata": {
        "id": "xfOkc3NIscKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution Code"
      ],
      "metadata": {
        "id": "no3kG1lVBXfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Code Attempt"
      ],
      "metadata": {
        "id": "OGkG2nXf1er9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class Conv2dCustom(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    in_channels: int,\n",
        "    out_channels: int,\n",
        "    kernel_size: tuple[int, int] = (1, 1),\n",
        "    stride: tuple[int, int] = (1, 1),\n",
        "    padding: tuple[int, int] = (0, 0),\n",
        "    dilation: tuple[int, int] = (1, 1),\n",
        "  ):\n",
        "    super().__init__()\n",
        "\n",
        "    # save hyperparams\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.dilation = dilation\n",
        "\n",
        "    # init weights\n",
        "    # https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter\n",
        "    self.weight = nn.Parameter(\n",
        "        torch.Tensor(out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
        "        )\n",
        "\n",
        "    # Init weight by Kaiming Uniform (same as in PyTorch),\n",
        "    # by logic it's Xavier\n",
        "    # read more: https://github.com/galkinc/ml-projects-lab/blob/main/foundations/pytorch-coding-challenges/medium_tasks/implement_parameter_initialization_for_cnn.ipynb\n",
        "    nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "\n",
        "  def add_padding(self, input_tensor):\n",
        "    padding = self.padding\n",
        "    if  padding == (0, 0):\n",
        "      return input_tensor\n",
        "\n",
        "    if len(padding) == 4:\n",
        "      return F.pad(input_tensor, padding, mode='constant', value=0)\n",
        "\n",
        "    pad_height, pad_width = padding\n",
        "    # F.pad expects to be filled in the format: [left, right, top, bottom]\n",
        "    padding_tuple = (pad_width, pad_width, pad_height, pad_height)\n",
        "\n",
        "    return F.pad(input_tensor, padding_tuple, mode='constant', value=0)\n",
        "\n",
        "  def calculate_output_size(self, input_size):\n",
        "    # output_size = floor((input_size + 2*padding - dilation*(kernel_size-1) - 1) / stride + 1)\n",
        "    def calc_dim(input_dim, kernel, stride, pad, dil):\n",
        "        return (input_dim + 2 * pad - dil * (kernel - 1) - 1) // stride + 1\n",
        "\n",
        "    # expand values\n",
        "    height, width = input_size\n",
        "    kernel_h, kernel_w = self.kernel_size\n",
        "    stride_h, stride_w = self.stride\n",
        "    pad_h, pad_w = self.padding\n",
        "    dilation_h, dilation_w = self.dilation\n",
        "\n",
        "    out_h = calc_dim(height, kernel_h, stride_h, pad_h, dilation_h)\n",
        "    out_w = calc_dim(width, kernel_w, stride_w, pad_w, dilation_w)\n",
        "    return out_h, out_w\n",
        "\n",
        "  def create_output_tensor(self, input_tensor):\n",
        "    batch_size = input_tensor.shape[0]\n",
        "    input_height, input_width = input_tensor.shape[2], input_tensor.shape[3]\n",
        "    output_size = self.calculate_output_size(input_size=(input_height, input_width))\n",
        "\n",
        "    out_height, out_width = output_size\n",
        "\n",
        "    # create a tensor with a normal shape and on the same device\n",
        "    return torch.empty(\n",
        "        batch_size,\n",
        "        self.out_channels,\n",
        "        out_height,\n",
        "        out_width,\n",
        "        device=input_tensor.device,\n",
        "        dtype=input_tensor.dtype\n",
        "    )\n",
        "\n",
        "  def conv_implementation(self, x_padded, output):\n",
        "    in_channels = self.in_channels\n",
        "    batch_size, _, in_height, in_width = x_padded.shape\n",
        "    kernel_h, kernel_w = self.kernel_size\n",
        "    stride_h, stride_w = self.stride\n",
        "\n",
        "    out_height = output.shape[2]\n",
        "    out_width = output.shape[3]\n",
        "\n",
        "    for oc in range(self.out_channels):\n",
        "      for b in range(batch_size):\n",
        "          for oh in range(out_height):\n",
        "              for ow in range(out_width):\n",
        "                # Calculate the starting position of the window in the input tensor\n",
        "                h_start = oh * stride_h\n",
        "                w_start = ow * stride_w\n",
        "                h_end = h_start + kernel_h\n",
        "                w_end = w_start + kernel_w\n",
        "\n",
        "                # Extracting a window from the input tensor\n",
        "                window = x_padded[b, :, h_start:h_end, w_start:w_end] # window shape: [in_channels, kernel_h, kernel_w]\n",
        "\n",
        "                # We get the weights for the current output channel\n",
        "                weights = self.weight[oc]  # shape: [in_channels, kernel_h, kernel_w]\n",
        "\n",
        "                # Convolution calculation - element-wise multiplication and summation of all elements of the resulting tensor\n",
        "                result = torch.sum(window* weights)\n",
        "                output[b, oc, oh, ow] = result\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "      # 1. Add padding\n",
        "      x_padded = self.add_padding(x)\n",
        "\n",
        "      # 2. Calculate size of the output tensor and prepare it\n",
        "      output = self.create_output_tensor(x)\n",
        "\n",
        "      # 3. Custom convolution\n",
        "      output = self.conv_implementation(x_padded, output)\n",
        "\n",
        "      return output\n",
        ""
      ],
      "metadata": {
        "id": "xyJ1gdrhvNNc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full solution code"
      ],
      "metadata": {
        "id": "g2rBrSMG1kBL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yIRCvBJXpUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "| Solution Checking | Target | Result | Status |\n",
        "|----------|------------|----------|--------|\n",
        "| Conv2D  | 0.2770     | 71.13%   | âœ… **Best** |\n",
        "| CustomConv2D | 2.3027     | 10.00%   | ðŸ”´ **Failed** |\n",
        "| Conv2D + MaxPool2d | 57.3428    | 28.92%   | ðŸŸ¡ **Poor** |\n",
        "| CustomConv2D + MaxPool2d | 57.3428    | 28.92%   | ðŸŸ¡ **Poor** |\n",
        "| Conv2D + CustomMaxPool2d  | 0.1859     | 70.12%   | ðŸŸ¢ **Good** |\n",
        "| CustomConv2D + CustomMaxPool2d  | 0.1859     | 70.12%   | ðŸŸ¢ **Good** |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aQV9A8as4AYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Thinking notes\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "cJiwhJULEayX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interesting Publications"
      ],
      "metadata": {
        "id": "k3fMyY5EFPhK"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4L12POpZPL2K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}