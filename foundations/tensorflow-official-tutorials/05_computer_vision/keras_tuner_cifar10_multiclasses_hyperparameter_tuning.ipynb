{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[blog.tensorflow.org](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Keras Tuner](https://github.com/keras-team/keras-tuner) is an easy-to-use, distributable hyperparameter optimization framework that solves the pain points of performing a hyperparameter search.\n",
    "Keras Tuner makes it easy to define a search space and leverage included algorithms to find the best hyperparameter values.\n",
    "\n",
    "Keras Tuner comes with Bayesian Optimization, Hyperband, and Random Search algorithms built-in, and is also designed to be easy for researchers to extend in order to experiment with new search algorithms.\n",
    "\n",
    "Here’s a simple end-to-end example. First, we define a model-building function. It takes an hp argument from which you can sample hyperparameters, such as hp.Int('units', min_value=32, max_value=512, step=32) (an integer from a certain range). Notice how the hyperparameters can be defined inline with the model-building code. The example below creates a simple tunable model that we’ll train on CIFAR-10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 10:45:01.482564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 10:45:02.137491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# takes an hp argument from which you can sample hyperparameters,\n",
    "# such as hp.Int('units', min_value=32, max_value=512, step=32) (an integer from a certain range)\n",
    "def build_model(hp):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(hp.Int('conv_blocks', 3, 5, default=3)):\n",
    "        filters = hp.Int('filters_' + str(i), 32, 256, step=32)\n",
    "\n",
    "        for _ in range(2):\n",
    "            x = tf.keras.layers.Convolution2D(\n",
    "                filters, kernel_size=(3, 3), padding='same')(x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "        if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\n",
    "            x = tf.keras.layers.MaxPool2D()(x)\n",
    "        else:\n",
    "            x = tf.keras.layers.AvgPool2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        hp.Int('hidden_size', 30, 100, step=10, default=50),\n",
    "        activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(\n",
    "        hp.Float('dropout', 0, 0.5, step=0.1, default=0.5))(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:44:10.090520Z",
     "end_time": "2023-05-09T09:44:11.776942Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, instantiate a tuner. You should specify the model-building function, and the name of the objective to optimize (whether to minimize or maximize is automatically inferred for built-in metrics -- for custom metrics you can specify this via the kerastuner.Objective class). In this example, Keras tuner will use the Hyperband algorithm for the hyperparameter search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "#import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    hyperband_iterations=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:49:29.340082Z",
     "end_time": "2023-05-09T09:49:31.368594Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we’ll download the CIFAR-10 dataset using [TensorFlow Datasets](https://www.tensorflow.org/datasets), and then begin the hyperparameter search. To start the search, call the search method. This method has the same signature as 'keras.Model.fit'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 10:45:05.222711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:05.257853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:05.257944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:05.260166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:05.260236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:05.260272: I tensorflow/compile"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function standardize_record at 0x7f6ee98bfe50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function standardize_record at 0x7f6ee98bfe50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:06.002247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:06.002366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:06.002379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-09 10:45:06.002425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-09 10:45:06.002451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function standardize_record at 0x7f6ee98bfe50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function standardize_record at 0x7f6ee98bfe50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function standardize_record at 0x7f6ee98bfe50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function standardize_record at 0x7f6ee98bfe50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 768 ms, sys: 312 ms, total: 1.08 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data = tfds.load('cifar10')\n",
    "train_ds, test_ds = data['train'], data['test']\n",
    "\n",
    "def standardize_record(record):\n",
    "    return tf.cast(record['image'], tf.float32) / 255., record['label']\n",
    "\n",
    "train_ds = train_ds.map(standardize_record).cache().batch(64).shuffle(10000)\n",
    "test_ds = test_ds.map(standardize_record).cache().batch(64)\n",
    "\n",
    "tuner.search(train_ds,\n",
    "             validation_data=test_ds,\n",
    "             epochs=30,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:45:04.762052Z",
     "end_time": "2023-05-09T09:45:06.497682Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each model will train for at most 30 epochs, and two iterations of the Hyperband algorithm will be run. Afterwards, you can retrieve the best models found during the search by using the get_best_models function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 462 ms, sys: 57.1 ms, total: 520 ms\n",
      "Wall time: 620 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x7f6eea54f220>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "# You can also view the optimal hyperparameter values found by the search:\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:45:06.451635Z",
     "end_time": "2023-05-09T09:45:07.026867Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Built-in Tunable Models\n",
    "In addition to allowing you to define your own tunable models, Keras Tuner provides two built-in tunable models: HyperResnet and HyperXception.\n",
    "\n",
    "These models search over various permutations of the ResNet and Xception architectures, respectively.\n",
    "These models can be used with a Tuner like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner[bayesian] in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (1.3.5)\r\n",
      "Requirement already satisfied: packaging in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner[bayesian]) (23.0)\r\n",
      "Requirement already satisfied: requests in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner[bayesian]) (2.28.2)\r\n",
      "Requirement already satisfied: kt-legacy in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner[bayesian]) (1.0.5)\r\n",
      "Requirement already satisfied: scikit-learn in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner[bayesian]) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner[bayesian]) (1.10.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner[bayesian]) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner[bayesian]) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner[bayesian]) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner[bayesian]) (2022.12.7)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn->keras-tuner[bayesian]) (1.23.5)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn->keras-tuner[bayesian]) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/galkinc/miniconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn->keras-tuner[bayesian]) (3.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Please install scikit-learn (sklearn) before using the `BayesianOptimization` with `pip install keras-tuner[bayesian]\n",
    "!pip install keras-tuner[bayesian]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:45:07.030865Z",
     "end_time": "2023-05-09T09:45:08.605230Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 46.2 ms, total: 1.15 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tuner = kt.tuners.BayesianOptimization(\n",
    "    kt.applications.HyperResNet(input_shape=(256, 256, 3), classes=10),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=50,\n",
    "    project_name='untitled2'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:48:21.593742Z",
     "end_time": "2023-05-09T09:48:22.862592Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Additional\n",
    "\n",
    "## Distributed Tuning\n",
    "With Keras Tuner, you can do both data-parallel and trial-parallel distribution. That is, you can use tf.distribute.Strategy to run each Model on multiple GPUs, and you can also search over multiple different hyperparameter combinations in parallel on different workers.\n",
    "\n",
    "No code changes are needed to perform a trial-parallel search. Simply set the KERASTUNER_TUNER_ID, KERASTUNER_ORACLE_IP, and KERASTUNER_ORACLE_PORT environment variables, for example as shown in the bash script here:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/mnt/d/gits/forecasting/TestProjects/Keras Tuner CIFAR-10 multiclasses/run_my_search.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!export KERASTUNER_TUNER_ID=\"chief\"\n",
    "!export KERASTUNER_ORACLE_IP=\"127.0.0.1\"\n",
    "!export KERASTUNER_ORACLE_PORT=\"8000\"\n",
    "!python run_my_search.py"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T09:48:44.245408Z",
     "end_time": "2023-05-09T09:48:45.096013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+The tuners coordinate their search via a central Oracle service that tells each tuner which hyperparameter values to try next.\n",
    "For more information, see our [Distributed Tuning guide](https://keras-team.github.io/keras-tuner/tutorials/distributed-tuning/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Training Loops\n",
    "\n",
    "The `kerastuner.Tuner` class can be subclassed to support advanced uses such as:\n",
    "* Custom training loops (GANs, reinforcement learning, etc.)\n",
    "* Adding hyperparameters outside of the model building function (preprocessing, data augmentation, test time augmentation, etc.)\n",
    "\n",
    "For more information, see our [Tuner Subclassing guide](https://keras-team.github.io/keras-tuner/tutorials/subclass-tuner/).\n",
    "\n",
    "Here’s a simple example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "\n",
    "    def run_trial(self, trial, ...):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        score = …  # Run the training loop and return the result.\n",
    "        self.oracle.update_trial(trial.trial_id, {'score': score})\n",
    "        self.oracle.save_model(trial.trial_id, model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning Scikit-learn Models\n",
    "Despite its name, Keras Tuner can be used to tune a wide variety of machine learning models. In addition to built-in Tuners for Keras models, Keras Tuner provides a built-in Tuner that works with Scikit-learn models. Here’s a simple example of how to use this tuner:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "\n",
    "def build_model(hp):\n",
    "    model_type = hp.Choice('model_type', ['random_forest', 'ridge'])\n",
    "    if model_type == 'random_forest':\n",
    "        with hp.conditional_scope('model_type', 'random_forest'):\n",
    "            model = ensemble.RandomForestClassifier(\n",
    "                n_estimators=hp.Int('n_estimators', 10, 50, step=10),\n",
    "                max_depth=hp.Int('max_depth', 3, 10))\n",
    "    elif model_type == 'ridge':\n",
    "        with hp.conditional_scope('model_type', 'ridge'):\n",
    "            model = linear_model.RidgeClassifier(\n",
    "                alpha=hp.Float('alpha', 1e-3, 1, sampling='log'))\n",
    "    else:\n",
    "        raise ValueError('Unrecognized model_type')\n",
    "    return model\n",
    "\n",
    "tuner = kt.tuners.Sklearn(\n",
    "    oracle=kt.oracles.BayesianOptimization(\n",
    "        objective=kt.Objective('score', 'max'),\n",
    "        max_trials=10),\n",
    "    hypermodel=build_model,\n",
    "    directory=tmp_dir)\n",
    "X, y = ...\n",
    "tuner.search(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For more information on Keras Tuner, please see the [Keras Tuner website](https://keras-team.github.io/keras-tuner/) or [the Keras Tuner GitHub](https://github.com/keras-team/keras-tuner). Keras Tuner is an open-source project developed entirely on GitHub. If there are features you’d like to see in Keras Tuner, please open a GitHub issue with a feature request, and if you’re interested in contributing, please take a look at our [contribution guidelines](https://keras-team.github.io/keras-tuner/contributing/).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
